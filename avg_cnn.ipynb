{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16893422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm # Displays a progress bar\n",
    "from math import sqrt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets, io, models, ops, transforms, utils\n",
    "from torch.utils.data import Dataset, Subset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "# from torchvision import datasets, io, models, ops, transforms, utils\n",
    "import os\n",
    "# import data as dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dae4358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the CPU. Overall speed may be slowed down\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Using the GPU. You are good to go!\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"Using the CPU. Overall speed may be slowed down\")\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bba52881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('output.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9204605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>filename</th>\n",
       "      <th>url</th>\n",
       "      <th>start_time</th>\n",
       "      <th>number_of_frames</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>label_proc</th>\n",
       "      <th>label_raw</th>\n",
       "      <th>label_notes</th>\n",
       "      <th>partition</th>\n",
       "      <th>signer</th>\n",
       "      <th>Label</th>\n",
       "      <th>start_l</th>\n",
       "      <th>end_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1800</td>\n",
       "      <td>deafvideo_4/mattref2005_5169</td>\n",
       "      <td>http://www.deafvideo.tv/805784</td>\n",
       "      <td>0:03:20.420000</td>\n",
       "      <td>6</td>\n",
       "      <td>640</td>\n",
       "      <td>360</td>\n",
       "      <td>iat</td>\n",
       "      <td>iat</td>\n",
       "      <td>iat?</td>\n",
       "      <td>train</td>\n",
       "      <td>37</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                      filename                             url   \n",
       "23        1800  deafvideo_4/mattref2005_5169  http://www.deafvideo.tv/805784  \\\n",
       "\n",
       "        start_time  number_of_frames  width  height label_proc label_raw   \n",
       "23  0:03:20.420000                 6    640     360        iat       iat  \\\n",
       "\n",
       "   label_notes partition  signer Label  start_l  end_l  \n",
       "23        iat?     train      37     a        2      3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[df['partition']=='dev']\n",
    "df[df['filename']=='deafvideo_4/mattref2005_5169']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec47fcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_exists(filename):\n",
    "    folders = ['avg_dev', 'avg_test', 'avg_train']\n",
    "    filename = filename.replace('/','_')+\".png\"\n",
    "    # print(filename)\n",
    "    for folder in folders:\n",
    "        if os.path.exists(os.path.join(folder, filename)):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "class HandSignDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, partition, transform=None):\n",
    "        self.df = pd.read_csv(csv_file, delimiter=';')\n",
    "        self.df = self.df[self.df['partition'] == partition]\n",
    "        self.df = self.df[self.df['filename'].apply(file_exists)]\n",
    "\n",
    "    # define a function to check if a file exists in any of the folders\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.df.iloc[idx, self.df.columns.get_loc('filename')]\n",
    "        filename_img = self.df.iloc[idx, self.df.columns.get_loc('filename')].replace('/','_')\n",
    "        label = self.df.iloc[idx, self.df.columns.get_loc('Label')]\n",
    "        label = ord(label) - 97\n",
    "        label = torch.tensor(label).long()\n",
    "        # if label != 'a' and label != 'b' and label != 'c' and label != 'd':\n",
    "        #     print(label)\n",
    "        image_path = os.path.join(self.root_dir, filename_img+\".png\")\n",
    "        bbox_path = os.path.join(\"BBox\", filename, \"0000.txt\")\n",
    "        \n",
    "        try:\n",
    "            with open(bbox_path) as f:\n",
    "                bbox_info = f.readline().split(',')\n",
    "                print(\"bbox_info\",bbox_info)\n",
    "            x0, y0, x1, y1, _ = bbox_info\n",
    "            x0, y0, x1, y1 = int(x0), int(y0), int(x1), int(y1)\n",
    "\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image = image.crop((x0, y0, x1, y1))\n",
    "        except FileNotFoundError:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "        if(np.sum(image)==0):\n",
    "            print('ALL ZERO')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        # print('image name: ',filename_img,\" | shape:\",image.shape,\" | label: \",label)\n",
    "#         utils.save_image(img, f\"/ImageOutput/{filename_img}_T.png\")\n",
    "        # img1 = img1.numpy() # TypeError: tensor or list of tensors expected, got <class 'numpy.ndarray'>\n",
    "#         save_image(img, filename +'_T.png')\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d6e6f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation(s) to be applied to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((360, 640)),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                          std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Call the create_dataset function to create a PyTorch dataset\n",
    "test_dataset = HandSignDataset(csv_file='output.csv', root_dir='avg_test', partition='test',transform=transform)\n",
    "train_dataset = HandSignDataset(csv_file='output.csv', root_dir='avg_train', partition='train',transform=transform)\n",
    "val_dataset = HandSignDataset(csv_file='output.csv', root_dir='avg_dev', partition='dev',transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0400812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# Create a data loader for the dataset\n",
    "\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, collate_fn=custom_collate)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51ca7db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in trainloader:\n",
    "    img = batch[0]\n",
    "    label = batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8d9134b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your network:\n"
     ]
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ##############################################################################\n",
    "        # TODO: Design your own network, define layers here.                          #\n",
    "        # Here We provide a sample of two-layer fc network from HW4 Part3.           #\n",
    "        # Your solution, however, should contain convolutional layers.               #\n",
    "        # Refer to PyTorch documentations of torch.nn to pick your layers.           #\n",
    "        # (https://pytorch.org/docs/stable/nn.html)                                  #\n",
    "        # Some common choices: Linear, Conv2d, ReLU, MaxPool2d, AvgPool2d, Dropout   #\n",
    "        # If you have many layers, use nn.Sequential() to simplify your code         #\n",
    "        ##############################################################################\n",
    "        # from 28x28 input image to hidden layer of size 256\n",
    "        # self.fc1 = nn.Linear(28*28, 8) \n",
    "        self.conv1 = nn.Conv2d(in_channels = 3,out_channels = 16,padding = 2, kernel_size = (5,5),stride = (2,2))\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 16,out_channels = 64, padding = 2,kernel_size = (5,5),stride = (2,2))\n",
    "        self.conv3 = nn.Conv2d(in_channels = 64,out_channels = 8, padding = 2,kernel_size = (5,5),stride = (2,2))\n",
    "        self.fc_1 = nn.Linear(in_features = 1760, out_features =800) \n",
    "        self.fc_2 = nn.Linear(in_features=800, out_features=200)\n",
    "        self.fc_3 = nn.Linear(in_features=200, out_features=4)\n",
    "        \n",
    "        self.init_weights()\n",
    "        ##############################################################################\n",
    "        #                             END OF YOUR CODE                               #\n",
    "        ##############################################################################\n",
    "    def init_weights(self):\n",
    "        \"\"\"Initialize all model parameters (weights and biases) in all layers to desired distributions\"\"\"\n",
    "\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        for conv in [self.conv1, self.conv2, self.conv3]:\n",
    "            C_in = conv.weight.size(1)\n",
    "            nn.init.normal_(conv.weight, 0.0, 1 / sqrt(5 * 5 * C_in))\n",
    "            nn.init.constant_(conv.bias, 0.0)\n",
    "\n",
    "        ## TODO: initialize the parameters for [self.fc_1]\n",
    "\n",
    "        nn.init.normal_(self.fc_1.weight, 0.0, sqrt(1/self.fc_1.weight.size(1)))\n",
    "        nn.init.constant_(self.fc_1.bias, 0.0)\n",
    "        ##\n",
    "\n",
    "    def forward(self, x):\n",
    "        ##############################################################################\n",
    "        # TODO: Design your own network, implement forward pass here                 # \n",
    "        ##############################################################################\n",
    "        \n",
    "        N, C, H, W = x.shape\n",
    "\n",
    "        ## TODO: forward pass\n",
    "        z= self.pool(F.relu(self.conv1(x)))\n",
    "        z= self.pool(F.relu(self.conv2(z)))\n",
    "        z = F.relu(self.conv3(z))\n",
    "\n",
    "        # z=z.permute(*torch.arange(z.ndim - 1, -1, -1))\n",
    "        # print(\"before flatten: \", z.shape)\n",
    "        z=torch.flatten(z, start_dim=1)\n",
    "\n",
    "        # print(\"after resize: \",z.shape) # 32 x 1760\n",
    "        z = self.fc_1(z)\n",
    "        z = self.fc_2(z)\n",
    "        z = self.fc_3(z)\n",
    "        # print(\"final shape: \", z.shape)\n",
    "\n",
    "        return z\n",
    "\n",
    "\n",
    "model = Network().to(device)\n",
    "criterion = nn.CrossEntropyLoss() # Specify the loss layer\n",
    "print('Your network:')\n",
    "# print(summary(model, (3,28,28), device=device)) # visualize your model\n",
    "\n",
    "##############################################################################\n",
    "# TODO: Modify the lines below to experiment with different optimizers,      #\n",
    "# parameters (such as learning rate) and number of epochs.                   #\n",
    "##############################################################################\n",
    "# Set up optimization hyperparameters\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-3\n",
    "num_epoch = 20  # TODO: Choose an appropriate number of training epochs\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate,\n",
    "                       weight_decay=weight_decay) # Try different optimizers\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e87118e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/wenxintian/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:02<00:00, 16.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "\n",
    "# Load the ResNet-18 model pretrained on ImageNet\n",
    "resnet18 = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa2d3b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((360, 640)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Call the create_dataset function to create a PyTorch dataset\n",
    "test_dataset = HandSignDataset(csv_file='output.csv', root_dir='avg_test', partition='test',transform=transform)\n",
    "train_dataset = HandSignDataset(csv_file='output.csv', root_dir='avg_train', partition='train',transform=transform)\n",
    "val_dataset = HandSignDataset(csv_file='output.csv', root_dir='avg_dev', partition='dev',transform=transform)\n",
    "\n",
    "batch_size = 32\n",
    "# Create a data loader for the dataset\n",
    "\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, collate_fn=custom_collate)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-3\n",
    "num_epoch = 10  # TODO: Choose an appropriate number of training epochs\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate,\n",
    "                       weight_decay=weight_decay) # Try different optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55421ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "-----------------Epoch = 1-----------------\n",
      "\n",
      " Epoch 1 loss:0.08959202491678298\n",
      "\n",
      " Evaluation accuracy: 0.9212598425196851\n",
      "\n",
      " Evaluate on validation set...\n",
      "\n",
      " Evaluation accuracy: 0.5263157894736842\n",
      "-----------------Epoch = 2-----------------\n",
      "\n",
      " Epoch 2 loss:0.11621750146150589\n",
      "\n",
      " Evaluation accuracy: 1.0\n",
      "\n",
      " Evaluate on validation set...\n",
      "\n",
      " Evaluation accuracy: 0.47368421052631576\n",
      "-----------------Epoch = 3-----------------\n",
      "\n",
      " Epoch 3 loss:0.025943502550944686\n",
      "\n",
      " Evaluation accuracy: 0.984251968503937\n",
      "\n",
      " Evaluate on validation set...\n",
      "\n",
      " Evaluation accuracy: 0.5263157894736842\n",
      "-----------------Epoch = 4-----------------\n",
      "\n",
      " Epoch 4 loss:0.03246304113417864\n",
      "\n",
      " Evaluation accuracy: 0.9921259842519685\n",
      "\n",
      " Evaluate on validation set...\n",
      "\n",
      " Evaluation accuracy: 0.5263157894736842\n",
      "-----------------Epoch = 5-----------------\n",
      "\n",
      " Epoch 5 loss:0.018899536167737097\n",
      "\n",
      " Evaluation accuracy: 1.0\n",
      "\n",
      " Evaluate on validation set...\n",
      "\n",
      " Evaluation accuracy: 0.47368421052631576\n",
      "-----------------Epoch = 6-----------------\n",
      "\n",
      " Epoch 6 loss:0.024401677888818085\n",
      "\n",
      " Evaluation accuracy: 0.9921259842519685\n",
      "\n",
      " Evaluate on validation set...\n",
      "\n",
      " Evaluation accuracy: 0.47368421052631576\n",
      "-----------------Epoch = 7-----------------\n",
      "\n",
      " Epoch 7 loss:0.017204964708071202\n",
      "\n",
      " Evaluation accuracy: 1.0\n",
      "\n",
      " Evaluate on validation set...\n",
      "\n",
      " Evaluation accuracy: 0.5263157894736842\n",
      "-----------------Epoch = 8-----------------\n",
      "\n",
      " Epoch 8 loss:0.017809731885790825\n",
      "\n",
      " Evaluation accuracy: 1.0\n",
      "\n",
      " Evaluate on validation set...\n",
      "\n",
      " Evaluation accuracy: 0.47368421052631576\n",
      "-----------------Epoch = 9-----------------\n",
      "\n",
      " Epoch 9 loss:0.003967481810832396\n",
      "\n",
      " Evaluation accuracy: 1.0\n",
      "\n",
      " Evaluate on validation set...\n",
      "\n",
      " Evaluation accuracy: 0.47368421052631576\n",
      "-----------------Epoch = 10-----------------\n",
      "\n",
      " Epoch 10 loss:0.004705423911218531\n",
      "\n",
      " Evaluation accuracy: 1.0\n",
      "\n",
      " Evaluate on validation set...\n",
      "\n",
      " Evaluation accuracy: 0.47368421052631576\n",
      "Done!\n",
      "\n",
      " Evaluate on test set\n",
      "\n",
      " Evaluation accuracy: 0.25\n",
      "CPU times: user 4min 35s, sys: 49.8 s, total: 5min 25s\n",
      "Wall time: 1min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "def train(model, trainloader, valloader, num_epoch=1):  # Train the model\n",
    "    print(\"Start training...\")\n",
    "    trn_loss_hist = []\n",
    "    trn_acc_hist = []\n",
    "    val_acc_hist = []\n",
    "    model.train()  # Set the model to training mode\n",
    "    for i in range(num_epoch):\n",
    "        running_loss = []\n",
    "        print('-----------------Epoch = %d-----------------' % (i+1))\n",
    "        for batch, label in trainloader:\n",
    "            # print('batch: ', len(batch))\n",
    "            # print(\"type: \", type(batch))\n",
    "            batch = batch.to(device)\n",
    "            # print(batch.shape)\n",
    "            # print('batch:' , lenbatch)\n",
    "            # print(\"label: \", label)\n",
    "            label = label.to(device)\n",
    "            # print('3')\n",
    "            optimizer.zero_grad()  # Clear gradients from the previous iteration\n",
    "            # This will call Network.forward() that you implement\n",
    "            pred = model(batch)\n",
    "            loss = criterion(pred, label)  # Calculate the loss\n",
    "            running_loss.append(loss.item())\n",
    "            loss.backward()  # Backprop gradients to all tensors in the network\n",
    "            optimizer.step()  # Update trainable weights\n",
    "        print(\"\\n Epoch {} loss:{}\".format(i+1, np.mean(running_loss)))\n",
    "\n",
    "        # Keep track of training loss, accuracy, and validation loss\n",
    "        trn_loss_hist.append(np.mean(running_loss))\n",
    "        trn_acc_hist.append(evaluate(model, trainloader))\n",
    "        print(\"\\n Evaluate on validation set...\")\n",
    "        val_acc_hist.append(evaluate(model, valloader))\n",
    "    print(\"Done!\")\n",
    "    return trn_loss_hist, trn_acc_hist, val_acc_hist\n",
    "\n",
    "\n",
    "def evaluate(model, loader):  # Evaluate accuracy on validation / test set\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    with torch.no_grad():  # Do not calculate grident to speed up computation\n",
    "        for batch, label in loader:\n",
    "            batch = batch.to(device)\n",
    "            # print(batch)\n",
    "            label = label.to(device)\n",
    "            pred = model(batch)\n",
    "            correct += (torch.argmax(pred, dim=1) == label).sum().item()\n",
    "        acc = correct/len(loader.dataset)\n",
    "        print(\"\\n Evaluation accuracy: {}\".format(acc))\n",
    "        return acc\n",
    "\n",
    "\n",
    "trn_loss_hist, trn_acc_hist, val_acc_hist = train(model, trainloader,\n",
    "                                                  valloader, num_epoch)\n",
    "\n",
    "##############################################################################\n",
    "# TODO: Note down the evaluation accuracy on test set                        #\n",
    "##############################################################################\n",
    "print(\"\\n Evaluate on test set\")\n",
    "evaluate(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e369699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('b') - 97  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
